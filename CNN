- CNN (합성곱 신경망)
    - 이미지, 비디오, 오디오 등 다차원 데이터를 처리하는 데 사용되는 딥러닝 모델
    - 입력 데이터의 공간적 구조를 고려하여 설계
    - 필터
        - 각 레이어의 입출력 데이터의 형상 유지
        - 복수의 필터로 이미지의 특징 추출 및 학습
        - 입력 데이터와 일치하는 부분을 강조하고 나머지 부분은 강조하지 않도록 가중치를 조절
        - 필터를 공유 파라미터로 사용하기 때문에, 일반 인공 신경망과 비교하여 학습 파라미터가 매우 적음
    - 합성곱층(Convolutional layer)
        - 입력 이미지의 특징을 추출하여 특징들의 패턴을 파악
        - 이미지의 공간 정보를 유지하면서 특징을 인식
    - 풀링층(Pooling layer)
        - 추출한 이미지의 특징을 모으고 강화하는 레이어
        - 합성곱층의 출력을 다운샘플링하여 처리량을 줄이는 역할
    - 완전연결층 (Fully Connected layer)
        - 마지막 출력을 처리하는데 사용
        - 이전 층에서 추출된 특징들을 결합하여 최종 출력을 생성
        
    - 영역
        - 특징 추출 영역
            - 합성곱층(필터적용, 활성화 함수 반영)과 풀링층(선택적)을 여러 겹 쌓은 상태
        - Flatten 레이어
            - 추출된 주요 특징을 전결합층에 전달하기 위해 이미지 형태의 데이터를 배열 형태 (1차원)로 flat
        - 클래스 분류 영역
            - CNN 마지막 부분에는 이미지 분류를 위한 완전 연결 계층 추가
        
    - 등장 배경
        - 다층 퍼셉트론(MLP)로 이미지를 flat하게 펼쳐 학습하면 이미지의 지역적 정보(topological information) 소실
            
            → 합성곱층의 뉴런은 수용 영역(receptive field) 안에 있는 픽셀에만 연결하여 이미지의 지역적 정보를 공유
            
        - 다층 퍼셉트론(MLP)은 해당 데이터를 추상화시키지 않고 바로 연산을 시작하기에 학습 시간과 능률이 비효율적
            
            → CNN은 이미지를 이해하고 추상화된 정보를 추출하여 특징(f과정
            
        - 다층 퍼셉트론은 이미지 픽셀마다 다른 가중치값을 부여하여, 픽셀값 하나만 달라져도 다르게 계산됨
            
            → 객체의 위치가 바뀌어도 같은 특징을 추출하도록 합성곱층에서는 각 영역의 인접 데이터를 조사해 특징을 파악
            
    - 구조
        - 사람의 시신경 구조를 모방한 구조
        - 데이터를 feature(특징, 차원)로 추출하여 패턴을 파악하는 구조
        - 유효 수용 필드 (receptive field)가 인간 눈의 중심과 매우 밀접한 관계가 있으며, 이는 날카로운 중심 시력, 원추 세포의 고밀도 영역 효과를 생성
            
            → CNN 네트워크에도 자연스럽게 존재. 특징의 패턴을 파악하여 인식
            
    - 과정
        - 초기 층은 이미지 픽셀을 저장하고, 마지막 층은 클래스 점수를 저장
        - 마지막 레이어층에는 각 클래스의 점수가 포함되고 각 항목의 레이블을 인쇄
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1b7428b5-1f80-40b3-aacc-73af246aa6d1/Untitled.png)
    
    - 활용
        - 딥러닝에서 심층 신경망으로 분류되며, 시각적 영상 분석에 주로 적용
        - 동영상 인식과 분류, 추천 시스템, 의료 영상 분석, 정보 추출, 문장 분류, 얼굴 인식 및 자연어 처리 등에 활용
    

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ff75c5b2-0220-44ed-932f-55783b222a07/Untitled.png)

<주요 용어 정리>

- 채널 (Channel)
    - 이미지 픽셀 하나하나는 실수(float)이며, 이미지 형태는 높이, 폭, 채널로 구성
    - 컬러 사진은 천연색을 표현하기 위해 각 픽셀을 RGB 3개의 실수로 표현한 3차원 데이터로 3개의 채널로 구성
    - 흑백 사진은 흑백 명암만을 표현하는 2차원 데이터로 1개 채널로 구성
    
    → 입력 데이터에는 한 개 이상의 필터가 적용되며, 1개 필터는 특징맵(Feature Map)의 채널이 됨
    
    합성곱층에 n개의 필터가 적용된다면 출력 데이터는 n개의 채널을 생성
    
- 합성곱 (Convolution)
    - 데이터의 특징을 추출하는 과정으로 필터를 사용하여 각 영역의 인접 데이터를 조사해 특징을 파악하여 한 장으로 도출
    
    → 여기서 도출된 장을 합성곱층(Convolution layer)로 명명
    
    - 추상화
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d884706d-35ec-4e64-911d-4e85ddc58982/Untitled.png)
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/628900e4-5ebd-4f1c-8715-7f05b5ead6fb/Untitled.png)
    
    - 이미지의 특정 부분을 추상화하여 특정 층으로 표현
    - 하나의 압축 과정으로 파라미터의 개수를 효과적으로 축소
    - 구조
        - 필터(Filter)
            - 특징이 데이터에 있는지 없는지를 검출하여 가중치 부여
            - 합성곱층 내 수용영역 생성, 필터 또는 커널이라 혼용하여 명명
        - 활성화함수
            - 특징 유무를 수치화하기 위해 비선형 값으로 바꿔주는 함수
    
- 필터
    - 이미지의 특징을 찾아내기 위한 공용 파라미터
    - 학습의 대상
    - 합성곱의 가중치
    - 실제로 커널이 가중치 합산하는 영역의 크기
    - 입력 데이터를 지정된 간격으로 순회하며 채널별로 합성곱을 하고 특징맵을 생성
- 커널
    - sliding window 하는 영역에서의 크기

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/741f3873-92a0-475b-ba0a-a27c000e32e3/Untitled.png)

- 스트라이드 (stride)
    - 필터를 적용하는 간격
    - 필터는 입력 데이터를 스트라이드 간격으로 순회하면서 합성곱을 계산
    - stride를 높일수록 공간적으로 더 작은 출력 볼륨이 생성 (but 데이터 손실 고려 필요)

- 패딩 (Padding)
    - 합성곱층의 출력 데이터의 사이즈를 조절하는 기능
    - 합성곱층에서 필터와 스트라이드 작용으로 특징 맵의 크기는 입력데이터보다 작아짐 (손실 발생) → 이를 위해 입력 데이터의 외곽게 지정된 픽셀만큼 특정 값으로 채워넣음 (패딩)

- 특징맵 (Feature Map)
    - 합성곱층의 입력 데이터를 필터과 순회하며 합성곱을 통해서 만든 출력 → 입력 데이터에서 필터를 통해 불필요한 정보를 걸러내고 중요한 신호만을 추출한 것

- 액티베이션 맵 (Activation Map)
    - 필터를 통해 추출된 피쳐 맵에 활성화 함수(Activation function)를 적용한 최종 출력층
    - 활성화 함수: 특징 맵의 정량적인 값을 비선형 값으로 바꿔주는 과정

- 풀링 (pooling)
    - 합성곱층에서 받은 최종 출력 데이터의 크기를 줄이거나 특정 데이터를 강조 → 데이터의 사이즈를 줄여주며 노이즈를 상쇄시키고, 미세한 부분에서 일관적인 특징을 제공
    - 풀링 레이어를 처리하는 방법: Max pooling(최대값), Average pooling(평균값), Min pooling(최소값)
    - 학습 대상 파라미터(필터)가 없음
    - 풀링층을 통과하면 행렬의 크기 감소
    - 풀링층을 통한 채널 수 변경 없음
    
- 드롭아웃 (Dropout)
    - AlexNet에서 선보인 과대적합을 막기 위한 방법
    - 신경망이 학습중일때, 무작위로 뉴런을 제거하여 학습을 방해함으로 학습 데이터에 과대적합을 방지
    - 일반적으로 CNN에서는 이 드롭아웃 레이어를 완전 연결 계층 뒤에 위치

- 데이터 증강 (Data augmentation)
    - 학습 데이터가 적어서 과대적합이 우려될 때, 기준 데이터로부터 이미지를 랜덤하게 생성하여 데이터의 수를 증강
    - train dataset에만 적용하며, 숫자의 경우 형태 변경으로 의미가 바뀔 수도 있어 주의해야 함
